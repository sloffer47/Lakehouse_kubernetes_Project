

# üöÄ Projet Lakehouse sur Kubernetes

**Migration compl√®te d‚Äôun pipeline Data Lakehouse vers Kubernetes (Kafka ‚Üí Spark ‚Üí Argo Workflows)**

---

## üß≠ Sommaire

1. [Pr√©sentation du projet](#-pr√©sentation-du-projet)
2. [Architecture globale](#-architecture-globale)
3. [Flux de donn√©es](#-flux-de-donn√©es)
4. [Structure du projet](#-structure-du-projet)
5. [√âtapes d‚Äôinstallation et d‚Äôex√©cution](#-√©tapes-dinstallation-et-dex√©cution)

   * [Version A ‚Äî Pipeline manuel (Kafka ‚Üí Spark)](#version-a--pipeline-manuel-kafka--spark)
   * [Version B ‚Äî Pipeline orchestr√© avec Argo Workflows](#version-b--pipeline-orchestr√©-avec-argo-workflows)
6. [Validation et r√©sultats finaux](#-validation-et-r√©sultats-finaux)
7. [Technologies utilis√©es](#-technologies-utilis√©es)
8. [Auteur](#-auteur)

---

## üß© Pr√©sentation du projet

Ce projet a pour objectif de **d√©ployer une architecture Lakehouse compl√®te sur Kubernetes**, de bout en bout :

* Ingestion **temps r√©el** avec **Kafka**
* Transformation et stockage **multi-couches (Bronze, Silver, Gold)** avec **Apache Spark**
* Stockage persistant via **PersistentVolumeClaim (PVC)**
* Orchestration optionnelle avec **Argo Workflows**

L‚Äôensemble est packag√© sous forme de **Jobs Kubernetes**, permettant un d√©ploiement reproductible sur n‚Äôimporte quel cluster (Docker Desktop, Minikube, Kind, etc.).

---

## üèóÔ∏è Architecture globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CLUSTER KUBERNETES                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                             ‚îÇ
‚îÇ  1. KAFKA (Message Broker)                  ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Kafka Broker (Port 9092)            ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Zookeeper (Port 2181)               ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  2. PRODUCER (G√©n√©rateur de donn√©es)        ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Job Kubernetes (Producer Java)      ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  3. SPARK JOBS (Traitements ETL)            ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Bronze : donn√©es brutes depuis Kafka‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Silver : nettoyage et validation    ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Gold : agr√©gations statistiques     ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  4. STORAGE (Lakehouse)                     ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ PersistentVolume (10Gi)             ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  5. ARGO WORKFLOWS (Orchestration) ‚öôÔ∏è       ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Ex√©cution s√©quentielle automatique  ‚îÇ
‚îÇ                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Structure du projet

```
lakehouse-kubernetes-project/
‚îú‚îÄ‚îÄ producer/                      # Producteur Kafka (Java)
‚îÇ   ‚îú‚îÄ‚îÄ Producer.java
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ pom.xml
‚îÇ
‚îú‚îÄ‚îÄ spark-jobs/                    # Jobs Spark (Scala)
‚îÇ   ‚îú‚îÄ‚îÄ Bronze.scala
‚îÇ   ‚îú‚îÄ‚îÄ Silver.scala
‚îÇ   ‚îú‚îÄ‚îÄ Gold.scala
‚îÇ   ‚îî‚îÄ‚îÄ pom.xml
‚îÇ
‚îú‚îÄ‚îÄ kubernetes/                    # Manifests Kubernetes
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îú‚îÄ‚îÄ kafka-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ topic-creation.yaml
‚îÇ   ‚îú‚îÄ‚îÄ producer-job.yaml
‚îÇ   ‚îú‚îÄ‚îÄ storage.yaml
‚îÇ   ‚îú‚îÄ‚îÄ spark-jobs.yaml
‚îÇ   ‚îî‚îÄ‚îÄ spark-applications.yaml
‚îÇ
‚îú‚îÄ‚îÄ argo/                          # (Optionnel) Orchestration
‚îÇ   ‚îî‚îÄ‚îÄ workflow.yaml
‚îÇ
‚îú‚îÄ‚îÄ build.sh                       # Script d'installation rapide
‚îú‚îÄ‚îÄ setup.py                       # Configuration Python (si besoin)
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è √âtapes d‚Äôinstallation et d‚Äôex√©cution

---

### üÖ∞Ô∏è Version A ‚Äî Pipeline manuel (Kafka ‚Üí Spark)

#### 1Ô∏è‚É£ D√©ployer Kafka

```bash
kubectl apply -f kubernetes/kafka-deployment.yaml
kubectl get pods -n lakehouse -w
```

Attendre que les pods soient `Running` :
`zookeeper`, `kafka`, et `create-topics` compl√©t√©.

#### 2Ô∏è‚É£ V√©rifier le topic

```bash
kubectl exec -it kafka-xxx -n lakehouse -- kafka-topics --bootstrap-server localhost:9092 --list
# R√©sultat attendu : vehicles-events
```

#### 3Ô∏è‚É£ Compiler et builder l‚Äôimage du Producer

```bash
cd producer
mvn clean package
docker build -t producer:1.0 .
```

#### 4Ô∏è‚É£ D√©ployer le Producer

```bash
kubectl apply -f kubernetes/producer-job.yaml
kubectl get jobs -n lakehouse -w
# Attendre : "producer-job 1/1 Completed"
```

#### 5Ô∏è‚É£ D√©ployer le stockage

```bash
kubectl apply -f kubernetes/storage.yaml
```

#### 6Ô∏è‚É£ Lancer les jobs Spark

```bash
kubectl apply -f kubernetes/spark-jobs.yaml
kubectl get jobs -n lakehouse -w
```

üü¢ Attendu :

```
producer-job   Complete   1/1
bronze-job     Complete   1/1
silver-job     Complete   1/1
gold-job       Complete   1/1
```

---

### üÖ±Ô∏è Version B ‚Äî Pipeline orchestr√© avec Argo Workflows

#### 1Ô∏è‚É£ Installer Argo Workflows

```bash
helm repo add argo https://argoproj.github.io/argo-helm
helm repo update
helm install argo-workflows argo/argo-workflows \
  -n argo-workflows --create-namespace \
  --set server.serviceType=LoadBalancer
```

#### 2Ô∏è‚É£ Cr√©er le Workflow

```bash
kubectl apply -f argo/workflow.yaml -n argo-workflows
```

#### 3Ô∏è‚É£ V√©rifier le Workflow

```bash
kubectl get workflows -n argo-workflows -w
```

Les t√¢ches doivent s‚Äôencha√Æner dans cet ordre :

> `producer ‚Üí bronze ‚Üí silver ‚Üí gold`

---

## üìä Validation et r√©sultats finaux

#### üîç V√©rifier les r√©sultats Spark Gold

```bash
kubectl exec -it gold-job-driver -n lakehouse -- bash
cd /data/gold/stats
ls
```

#### üî¢ Lire les donn√©es avec Spark

```bash
spark-shell
scala> val df = spark.read.parquet("/data/gold/stats")
scala> df.show()
```

‚úÖ Exemple de sortie :

```
+------+-------+-----------+-----------+
| type | total | avg_battery | max_lat |
+------+-------+-------------+----------+
| car  | 10    | 75.4        | 48.90    |
| bike | 10    | 67.1        | 48.92    |
| scoot| 10    | 82.3        | 48.95    |
+------+-------+-------------+----------+
```

---

## üß∞ Technologies utilis√©es

| Composant      | R√¥le                    | Technologie    |
| -------------- | ----------------------- | -------------- |
| Messaging      | Streaming temps r√©el    | Apache Kafka   |
| Ingestion      | G√©n√©ration d‚Äô√©v√©nements | Producer Java  |
| Traitement     | ETL / Lakehouse         | Apache Spark   |
| Orchestration  | Pipelines automatiques  | Argo Workflows |
| Infrastructure | D√©ploiement distribu√©   | Kubernetes     |
| Stockage       | Donn√©es persistantes    | PVC / HostPath |

---

## üë®‚Äçüíª Auteur

**Ton MBANDOU Yorick**
Projet r√©alis√© dans le cadre du module *Cloud & Big Data Engineering*

