# Data Lakehouse Migration vers Kubernetes

Architecture complÃ¨te pour migrer un pipeline data de Docker Compose vers Kubernetes.

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       KUBERNETES CLUSTER                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  1. KAFKA (Message Broker)                  â”‚
â”‚     â”œâ”€â”€ Kafka Broker (Port 9092)            â”‚
â”‚     â””â”€â”€ Zookeeper (Port 2181)               â”‚
â”‚                                             â”‚
â”‚  2. PRODUCER (GÃ©nÃ©rateur de donnÃ©es)        â”‚
â”‚     â””â”€â”€ Job Kubernetes                      â”‚
â”‚                                             â”‚
â”‚  3. SPARK JOBS (Traitement)                 â”‚
â”‚     â”œâ”€â”€ Bronze (DonnÃ©es brutes)             â”‚
â”‚     â”œâ”€â”€ Silver (DonnÃ©es nettoyÃ©es)          â”‚
â”‚     â””â”€â”€ Gold (Statistiques)                 â”‚
â”‚                                             â”‚
â”‚  4. STORAGE (DonnÃ©es persistantes)          â”‚
â”‚     â””â”€â”€ PersistentVolume                    â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. PrÃ©requis
- Kubernetes (Docker Desktop, Minikube, Kind)
- kubectl configurÃ©
- Maven (pour compiler le Producer)
- Docker Desktop / Docker CLI

### 2. Structure du Projet

```
lakehouse-kubernetes-project/
â”œâ”€â”€ producer/              # Code Java du Producer
â”‚   â”œâ”€â”€ Producer.java      # Source
â”‚   â”œâ”€â”€ pom.xml           # DÃ©pendances Maven
â”‚   â””â”€â”€ Dockerfile        # Build Docker
â”œâ”€â”€ spark-jobs/            # Jobs Spark (Python)
â”‚   â”œâ”€â”€ bronze.py         # Lecture Kafka
â”‚   â”œâ”€â”€ silver.py         # Nettoyage
â”‚   â””â”€â”€ gold.py           # AgrÃ©gations
â”œâ”€â”€ kubernetes/            # Configuration K8s
â”‚   â”œâ”€â”€ namespace.yaml     # Namespace
â”‚   â”œâ”€â”€ kafka-deployment.yaml
â”‚   â”œâ”€â”€ topic-creation.yaml
â”‚   â”œâ”€â”€ producer-job.yaml
â”‚   â”œâ”€â”€ storage.yaml
â”‚   â””â”€â”€ spark-jobs.yaml
â””â”€â”€ README.md             # Ce fichier
```

### 3. Ã‰tapes de DÃ©ploiement

#### Ã‰tape 1 : CrÃ©er le namespace
```bash
kubectl apply -f kubernetes/namespace.yaml
```

#### Ã‰tape 2 : DÃ©ployer Kafka
```bash
kubectl apply -f kubernetes/kafka-deployment.yaml
kubectl apply -f kubernetes/topic-creation.yaml

# Attends que les pods soient Running
kubectl get pods -n lakehouse -w
```

#### Ã‰tape 3 : Builder l'image Docker du Producer
```bash
cd producer
docker build -t producer:1.0 .
cd ..
```

#### Ã‰tape 4 : DÃ©ployer le Producer
```bash
kubectl apply -f kubernetes/producer-job.yaml

# VÃ©rifie que le job s'exÃ©cute
kubectl get jobs -n lakehouse -w
```

#### Ã‰tape 5 : VÃ©rifier les donnÃ©es dans Kafka
```bash
kubectl run -it --rm --restart=Never \
  --image=confluentinc/cp-kafka:7.4.0 \
  -n lakehouse test \
  -- kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic vehicles-events \
  --max-messages 5
```

#### Ã‰tape 6 : DÃ©ployer les jobs Spark
```bash
# D'abord, crÃ©er une ConfigMap avec les scripts Spark
kubectl create configmap spark-scripts \
  --from-file=spark-jobs/ \
  -n lakehouse

# Puis dÃ©ployer les jobs
kubectl apply -f kubernetes/spark-jobs.yaml
```

### 4. Monitoring

```bash
# Voir tous les pods
kubectl get pods -n lakehouse

# Voir les logs d'un pod
kubectl logs -n lakehouse <pod-name>

# Voir les jobs
kubectl get jobs -n lakehouse

# DÃ©crire une ressource
kubectl describe pod -n lakehouse <pod-name>
```

### 5. Nettoyage

```bash
# Supprimer tout
kubectl delete namespace lakehouse
```

## ğŸ“ˆ Flux de DonnÃ©es

1. **Producer** â†’ GÃ©nÃ¨re 30 Ã©vÃ©nements GPS
2. **Kafka** â†’ Stocke les Ã©vÃ©nements
3. **Bronze** â†’ Lit Kafka, Ã©crit Parquet brut
4. **Silver** â†’ Valide les donnÃ©es, filtre
5. **Gold** â†’ AgrÃ¨ge par type de vÃ©hicule

## ğŸ”§ Configuration

### Variables d'environnement

#### Producer
```
KAFKA_BOOTSTRAP_SERVER=kafka:9092  # URL Kafka
```

### Ressources Kubernetes

- **CPU Request**: 100m - 500m
- **Memory Request**: 256Mi - 1Gi
- **Storage**: 10Gi

## ğŸ“ Exemple de Message Kafka

```json
{
  "vehicleId": "CAR_000",
  "type": "car",
  "latitude": 48.8566,
  "longitude": 2.3522,
  "battery": 75,
  "timestamp": 1697203200000
}
```

## ğŸ¯ RÃ©sultats Attendus

### Bronze
- Lit les Ã©vÃ©nements Kafka
- Ã‰crit `/data/bronze/vehicles/part-*.parquet`
- 30 lignes minimum

### Silver
- Valide batterie (0-100)
- Valide coordonnÃ©es (lat: -90 Ã  90, lon: -180 Ã  180)
- Ã‰crit `/data/silver/vehicles/part-*.parquet`
- ~28-30 lignes (aprÃ¨s filtrage)

### Gold
- AgrÃ¨ge par type (car, bike, scooter)
- Calcule moyennes et min/max
- Ã‰crit `/data/gold/stats/part-*.parquet`
- 3 lignes (une par type)

## ğŸ› Troubleshooting

### Le Producer n'envoie pas de messages
```bash
# VÃ©rifier que Kafka est accessible
kubectl exec -it kafka-xxx -n lakehouse -- \
  kafka-broker-api-versions --bootstrap-server localhost:9092
```

### Les Spark jobs ne trouvent pas les donnÃ©es
```bash
# VÃ©rifier le PersistentVolume
kubectl get pv
kubectl describe pv data-pv

# VÃ©rifier le PersistentVolumeClaim
kubectl get pvc -n lakehouse
```

### Pas de messages dans Kafka
```bash
# Regarde les logs du Producer
kubectl logs -n lakehouse job/producer-job

# Regarde les logs de Kafka
kubectl logs -n lakehouse kafka-xxx
```

## ğŸ“š Ressources

- [Kafka Documentation](https://kafka.apache.org/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Spark Documentation](https://spark.apache.org/)

---

**CrÃ©Ã© avec â¤ï¸ pour la migration Kubernetes**
