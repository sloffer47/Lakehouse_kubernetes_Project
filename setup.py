#!/usr/bin/env python3
"""
Setup.py - GÃ©nÃ©rateur de Projet Data Lakehouse Kubernetes
CrÃ©e une structure complÃ¨te avec tous les fichiers nÃ©cessaires
"""

import os
import sys
from pathlib import Path

def create_directory(path):
    """CrÃ©e un rÃ©pertoire s'il n'existe pas"""
    Path(path).mkdir(parents=True, exist_ok=True)
    print(f"âœ“ CrÃ©Ã©: {path}")

def create_file(path, content):
    """CrÃ©e un fichier avec le contenu spÃ©cifiÃ©"""
    Path(path).parent.mkdir(parents=True, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"âœ“ Fichier: {path}")

def main():
    # Chemin du projet
    project_root = Path("C:/lakehouse-kubernetes-project")
    
    if project_root.exists():
        response = input(f"Le dossier {project_root} existe dÃ©jÃ . Continuer ? (y/n): ")
        if response.lower() != 'y':
            print("AnnulÃ©.")
            return
    
    print("\nğŸš€ GÃ©nÃ©ration du projet Data Lakehouse Kubernetes...\n")
    
    # CrÃ©er la structure de dossiers
    dirs = [
        project_root,
        project_root / "producer",
        project_root / "spark-jobs",
        project_root / "kubernetes",
        project_root / "docs",
    ]
    
    for dir_path in dirs:
        create_directory(dir_path)
    
    # ==================== FICHIERS PRODUCER JAVA ====================
    
    create_file(
        project_root / "producer" / "Producer.java",
        '''import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import com.fasterxml.jackson.databind.ObjectMapper;
import java.util.*;

/**
 * Producer Java pour Kafka
 * GÃ©nÃ¨re 30 Ã©vÃ©nements GPS simulÃ©s toutes les 3 secondes
 * Envoie les messages au topic "vehicles-events"
 */
public class Producer {
    public static void main(String[] args) throws Exception {
        // Configuration du producteur Kafka
        Properties props = new Properties();
        props.put("bootstrap.servers", System.getenv("KAFKA_BOOTSTRAP_SERVER"));
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("acks", "all");
        props.put("retries", "3");
        
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        ObjectMapper mapper = new ObjectMapper();
        Random random = new Random();
        
        String[] types = {"car", "bike", "scooter"};
        
        System.out.println("ğŸ“ DÃ©marrage du Producer...");
        System.out.println("ğŸ¯ Cible: " + props.getProperty("bootstrap.servers"));
        
        // GÃ©nÃ¨re 30 Ã©vÃ©nements
        for (int i = 0; i < 30; i++) {
            Map<String, Object> event = new HashMap<>();
            String type = types[i % 3];
            
            event.put("vehicleId", type.toUpperCase() + "_" + String.format("%03d", i));
            event.put("type", type);
            event.put("latitude", 48.8566 + (random.nextDouble() - 0.5) * 0.1);
            event.put("longitude", 2.3522 + (random.nextDouble() - 0.5) * 0.1);
            event.put("battery", 50 + random.nextInt(51));
            event.put("timestamp", System.currentTimeMillis());
            
            String json = mapper.writeValueAsString(event);
            producer.send(new ProducerRecord<>("vehicles-events", json));
            System.out.println("âœ“ Event " + (i+1) + "/30: " + json);
        }
        
        producer.flush();
        producer.close();
        System.out.println("âœ… 30 Ã©vÃ©nements envoyÃ©s Ã  Kafka");
    }
}
'''
    )
    
    create_file(
        project_root / "producer" / "pom.xml",
        '''<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0">
  <modelVersion>4.0.0</modelVersion>
  <groupId>com.kafka</groupId>
  <artifactId>producer</artifactId>
  <version>1.0</version>
  <packaging>jar</packaging>
  
  <!-- DÃ©pendances pour Kafka et JSON -->
  <dependencies>
    <!-- Kafka Client -->
    <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
      <version>3.4.0</version>
    </dependency>
    
    <!-- Jackson pour JSON -->
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>2.14.0</version>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <!-- Maven Shade Plugin pour crÃ©er un FAT JAR -->
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <version>3.2.4</version>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
            <configuration>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                  <mainClass>Producer</mainClass>
                </transformer>
              </transformers>
              <outputFile>${project.build.directory}/${project.artifactId}-${project.version}-fat.jar</outputFile>
            </configuration>
          </execution>
        </executions>
      </plugin>
    </plugins>
  </build>
</project>
'''
    )
    
    create_file(
        project_root / "producer" / "Dockerfile",
        '''# Stage 1: Build avec Maven
FROM maven:3.8.1-openjdk-11 AS builder
WORKDIR /app

# Copie et compile
COPY pom.xml .
RUN mvn dependency:resolve

COPY Producer.java .
RUN mvn clean package -DskipTests

# Stage 2: Runtime
FROM openjdk:11-jre-slim
WORKDIR /app

# Copie le JAR depuis le builder
COPY --from=builder /app/target/producer-1.0-fat.jar .

# Variable d'environnement pour Kafka
ENV KAFKA_BOOTSTRAP_SERVER=kafka:9092

# Lance le Producer
CMD ["java", "-jar", "producer-1.0-fat.jar"]
'''
    )
    
    # ==================== FICHIERS SPARK ====================
    
    create_file(
        project_root / "spark-jobs" / "bronze.py",
        '''"""
Bronze Layer - Lecture depuis Kafka
Lit les Ã©vÃ©nements bruts depuis Kafka et les Ã©crit en Parquet
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, schema_of_json

def main():
    # CrÃ©ation de la session Spark
    spark = SparkSession.builder \\
        .appName("bronze-layer") \\
        .getOrCreate()
    
    # SchÃ©ma JSON des Ã©vÃ©nements
    schema = "vehicleId STRING, type STRING, latitude DOUBLE, longitude DOUBLE, battery INT, timestamp LONG"
    
    # Lecture streaming depuis Kafka
    df = spark.readStream \\
        .format("kafka") \\
        .option("kafka.bootstrap.servers", "kafka:9092") \\
        .option("subscribe", "vehicles-events") \\
        .option("startingOffsets", "earliest") \\
        .load()
    
    print("ğŸ“¥ Bronze: Lecture depuis Kafka...")
    
    # Parse JSON et sÃ©lectionne les colonnes
    parsed_df = df.select(
        from_json(col("value"), schema).alias("data")
    ).select("data.*")
    
    # Ã‰criture en Parquet (streaming)
    query = parsed_df.writeStream \\
        .format("parquet") \\
        .option("path", "/data/bronze/vehicles") \\
        .option("checkpointLocation", "/data/bronze/checkpoint") \\
        .start()
    
    # Attends 60 secondes puis arrÃªte
    query.awaitTermination(60000)
    print("âœ… Bronze complÃ©tÃ©")

if __name__ == "__main__":
    main()
'''
    )
    
    create_file(
        project_root / "spark-jobs" / "silver.py",
        '''"""
Silver Layer - Nettoyage et validation
Filtre les donnÃ©es invalides (batterie, coordonnÃ©es)
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json

def main():
    spark = SparkSession.builder \\
        .appName("silver-layer") \\
        .getOrCreate()
    
    print("ğŸ§¹ Silver: Nettoyage des donnÃ©es...")
    
    # Lecture des donnÃ©es Bronze
    df = spark.read.parquet("/data/bronze/vehicles")
    
    # Parse JSON
    schema = "vehicleId STRING, type STRING, latitude DOUBLE, longitude DOUBLE, battery INT, timestamp LONG"
    parsed = df.select(from_json(col("value"), schema).alias("data")).select("data.*")
    
    # Filtres de validation
    cleaned = parsed \\
        .filter(col("battery").between(0, 100)) \\
        .filter(col("latitude").between(-90, 90)) \\
        .filter(col("longitude").between(-180, 180)) \\
        .filter(col("vehicleId").isNotNull()) \\
        .filter(col("type").isin("car", "bike", "scooter"))
    
    count_before = parsed.count()
    count_after = cleaned.count()
    
    print(f"ğŸ“Š Bronze: {count_before} lignes")
    print(f"âœ“ Silver: {count_after} lignes (${count_before - count_after} rejetÃ©es)")
    
    # Ã‰criture en Parquet
    cleaned.write.mode("overwrite").parquet("/data/silver/vehicles")
    print("âœ… Silver complÃ©tÃ©")

if __name__ == "__main__":
    main()
'''
    )
    
    create_file(
        project_root / "spark-jobs" / "gold.py",
        '''"""
Gold Layer - AgrÃ©gations et statistiques
GÃ©nÃ¨re les statistiques finales par type de vÃ©hicule
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, avg, min, max

def main():
    spark = SparkSession.builder \\
        .appName("gold-layer") \\
        .getOrCreate()
    
    print("ğŸ“ˆ Gold: AgrÃ©gation des donnÃ©es...")
    
    # Lecture des donnÃ©es Silver
    df = spark.read.parquet("/data/silver/vehicles")
    
    # AgrÃ©gations
    stats = df.groupBy("type").agg(
        count("*").alias("total"),
        avg("battery").alias("avg_battery"),
        min("latitude").alias("min_lat"),
        max("latitude").alias("max_lat"),
        min("longitude").alias("min_lon"),
        max("longitude").alias("max_lon")
    )
    
    # Affiche les rÃ©sultats
    print("\\nğŸ“Š Statistiques finales:")
    stats.show()
    
    # Ã‰criture en Parquet
    stats.write.mode("overwrite").parquet("/data/gold/stats")
    print("âœ… Gold complÃ©tÃ©")

if __name__ == "__main__":
    main()
'''
    )
    
    # ==================== FICHIERS KUBERNETES ====================
    
    create_file(
        project_root / "kubernetes" / "namespace.yaml",
        '''# CrÃ©e le namespace pour isoler le projet
apiVersion: v1
kind: Namespace
metadata:
  name: lakehouse
  labels:
    name: lakehouse
'''
    )
    
    create_file(
        project_root / "kubernetes" / "kafka-deployment.yaml",
        '''# DÃ©ploiement Kafka et Zookeeper
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zookeeper
  namespace: lakehouse
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:7.4.0
        ports:
        - containerPort: 2181
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  namespace: lakehouse
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.4.0
        ports:
        - containerPort: 9092
        env:
        - name: KAFKA_BROKER_ID
          value: "1"
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka:9092"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"

---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: lakehouse
spec:
  selector:
    app: kafka
  ports:
  - port: 9092
    targetPort: 9092
  clusterIP: None

---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: lakehouse
spec:
  selector:
    app: zookeeper
  ports:
  - port: 2181
    targetPort: 2181
  clusterIP: None
'''
    )
    
    create_file(
        project_root / "kubernetes" / "topic-creation.yaml",
        '''apiVersion: batch/v1
kind: Job
metadata:
  name: create-topics
  namespace: lakehouse
spec:
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      containers:
      - name: kafka-topic-creator
        image: confluentinc/cp-kafka:7.4.0
        command:
        - sh
        - -c
        - |
          sleep 20
          kafka-topics --create --bootstrap-server kafka:9092 --topic vehicles-events --partitions 1 --replication-factor 1 --if-not-exists
          echo "Topic created successfully"
      restartPolicy: Never
  backoffLimit: 3
'''
    )
    
    create_file(
        project_root / "kubernetes" / "producer-job.yaml",
        '''# Job Kubernetes pour le Producer
apiVersion: batch/v1
kind: Job
metadata:
  name: producer-job
  namespace: lakehouse
spec:
  template:
    spec:
      containers:
      - name: producer
        image: producer:1.0
        imagePullPolicy: Never
        env:
        - name: KAFKA_BOOTSTRAP_SERVER
          value: "kafka:9092"
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      restartPolicy: Never
  backoffLimit: 3
'''
    )
    
    create_file(
        project_root / "kubernetes" / "storage.yaml",
        '''# PersistentVolume et PersistentVolumeClaim pour Spark
apiVersion: v1
kind: PersistentVolume
metadata:
  name: data-pv
  namespace: lakehouse
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/data/lakehouse"

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-pvc
  namespace: lakehouse
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
'''
    )
    
    create_file(
        project_root / "kubernetes" / "spark-jobs.yaml",
        '''# Jobs Spark pour Bronze, Silver, Gold
apiVersion: batch/v1
kind: Job
metadata:
  name: bronze-job
  namespace: lakehouse
spec:
  template:
    spec:
      containers:
      - name: spark
        image: apache/spark:3.3.0
        command: ["spark-submit", "--master", "local[2]", "--deploy-mode", "client"]
        args: ["/scripts/bronze.py"]
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: data
          mountPath: /data
      volumes:
      - name: scripts
        configMap:
          name: spark-scripts
      - name: data
        persistentVolumeClaim:
          claimName: data-pvc
      restartPolicy: Never
  backoffLimit: 1

---
apiVersion: batch/v1
kind: Job
metadata:
  name: silver-job
  namespace: lakehouse
spec:
  template:
    spec:
      containers:
      - name: spark
        image: apache/spark:3.3.0
        command: ["spark-submit", "--master", "local[2]", "--deploy-mode", "client"]
        args: ["/scripts/silver.py"]
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: data
          mountPath: /data
      volumes:
      - name: scripts
        configMap:
          name: spark-scripts
      - name: data
        persistentVolumeClaim:
          claimName: data-pvc
      restartPolicy: Never
  backoffLimit: 1

---
apiVersion: batch/v1
kind: Job
metadata:
  name: gold-job
  namespace: lakehouse
spec:
  template:
    spec:
      containers:
      - name: spark
        image: apache/spark:3.3.0
        command: ["spark-submit", "--master", "local[2]", "--deploy-mode", "client"]
        args: ["/scripts/gold.py"]
        volumeMounts:
        - name: scripts
          mountPath: /scripts
        - name: data
          mountPath: /data
      volumes:
      - name: scripts
        configMap:
          name: spark-scripts
      - name: data
        persistentVolumeClaim:
          claimName: data-pvc
      restartPolicy: Never
  backoffLimit: 1
'''
    )
    
    # ==================== README ====================
    
    create_file(
        project_root / "README.md",
        '''# Data Lakehouse Migration vers Kubernetes

Architecture complÃ¨te pour migrer un pipeline data de Docker Compose vers Kubernetes.

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       KUBERNETES CLUSTER                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  1. KAFKA (Message Broker)                  â”‚
â”‚     â”œâ”€â”€ Kafka Broker (Port 9092)            â”‚
â”‚     â””â”€â”€ Zookeeper (Port 2181)               â”‚
â”‚                                             â”‚
â”‚  2. PRODUCER (GÃ©nÃ©rateur de donnÃ©es)        â”‚
â”‚     â””â”€â”€ Job Kubernetes                      â”‚
â”‚                                             â”‚
â”‚  3. SPARK JOBS (Traitement)                 â”‚
â”‚     â”œâ”€â”€ Bronze (DonnÃ©es brutes)             â”‚
â”‚     â”œâ”€â”€ Silver (DonnÃ©es nettoyÃ©es)          â”‚
â”‚     â””â”€â”€ Gold (Statistiques)                 â”‚
â”‚                                             â”‚
â”‚  4. STORAGE (DonnÃ©es persistantes)          â”‚
â”‚     â””â”€â”€ PersistentVolume                    â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. PrÃ©requis
- Kubernetes (Docker Desktop, Minikube, Kind)
- kubectl configurÃ©
- Maven (pour compiler le Producer)
- Docker Desktop / Docker CLI

### 2. Structure du Projet

```
lakehouse-kubernetes-project/
â”œâ”€â”€ producer/              # Code Java du Producer
â”‚   â”œâ”€â”€ Producer.java      # Source
â”‚   â”œâ”€â”€ pom.xml           # DÃ©pendances Maven
â”‚   â””â”€â”€ Dockerfile        # Build Docker
â”œâ”€â”€ spark-jobs/            # Jobs Spark (Python)
â”‚   â”œâ”€â”€ bronze.py         # Lecture Kafka
â”‚   â”œâ”€â”€ silver.py         # Nettoyage
â”‚   â””â”€â”€ gold.py           # AgrÃ©gations
â”œâ”€â”€ kubernetes/            # Configuration K8s
â”‚   â”œâ”€â”€ namespace.yaml     # Namespace
â”‚   â”œâ”€â”€ kafka-deployment.yaml
â”‚   â”œâ”€â”€ topic-creation.yaml
â”‚   â”œâ”€â”€ producer-job.yaml
â”‚   â”œâ”€â”€ storage.yaml
â”‚   â””â”€â”€ spark-jobs.yaml
â””â”€â”€ README.md             # Ce fichier
```

### 3. Ã‰tapes de DÃ©ploiement

#### Ã‰tape 1 : CrÃ©er le namespace
```bash
kubectl apply -f kubernetes/namespace.yaml
```

#### Ã‰tape 2 : DÃ©ployer Kafka
```bash
kubectl apply -f kubernetes/kafka-deployment.yaml
kubectl apply -f kubernetes/topic-creation.yaml

# Attends que les pods soient Running
kubectl get pods -n lakehouse -w
```

#### Ã‰tape 3 : Builder l'image Docker du Producer
```bash
cd producer
docker build -t producer:1.0 .
cd ..
```

#### Ã‰tape 4 : DÃ©ployer le Producer
```bash
kubectl apply -f kubernetes/producer-job.yaml

# VÃ©rifie que le job s'exÃ©cute
kubectl get jobs -n lakehouse -w
```

#### Ã‰tape 5 : VÃ©rifier les donnÃ©es dans Kafka
```bash
kubectl run -it --rm --restart=Never \\
  --image=confluentinc/cp-kafka:7.4.0 \\
  -n lakehouse test \\
  -- kafka-console-consumer \\
  --bootstrap-server kafka:9092 \\
  --topic vehicles-events \\
  --max-messages 5
```

#### Ã‰tape 6 : DÃ©ployer les jobs Spark
```bash
# D'abord, crÃ©er une ConfigMap avec les scripts Spark
kubectl create configmap spark-scripts \\
  --from-file=spark-jobs/ \\
  -n lakehouse

# Puis dÃ©ployer les jobs
kubectl apply -f kubernetes/spark-jobs.yaml
```

### 4. Monitoring

```bash
# Voir tous les pods
kubectl get pods -n lakehouse

# Voir les logs d'un pod
kubectl logs -n lakehouse <pod-name>

# Voir les jobs
kubectl get jobs -n lakehouse

# DÃ©crire une ressource
kubectl describe pod -n lakehouse <pod-name>
```

### 5. Nettoyage

```bash
# Supprimer tout
kubectl delete namespace lakehouse
```

## ğŸ“ˆ Flux de DonnÃ©es

1. **Producer** â†’ GÃ©nÃ¨re 30 Ã©vÃ©nements GPS
2. **Kafka** â†’ Stocke les Ã©vÃ©nements
3. **Bronze** â†’ Lit Kafka, Ã©crit Parquet brut
4. **Silver** â†’ Valide les donnÃ©es, filtre
5. **Gold** â†’ AgrÃ¨ge par type de vÃ©hicule

## ğŸ”§ Configuration

### Variables d'environnement

#### Producer
```
KAFKA_BOOTSTRAP_SERVER=kafka:9092  # URL Kafka
```

### Ressources Kubernetes

- **CPU Request**: 100m - 500m
- **Memory Request**: 256Mi - 1Gi
- **Storage**: 10Gi

## ğŸ“ Exemple de Message Kafka

```json
{
  "vehicleId": "CAR_000",
  "type": "car",
  "latitude": 48.8566,
  "longitude": 2.3522,
  "battery": 75,
  "timestamp": 1697203200000
}
```

## ğŸ¯ RÃ©sultats Attendus

### Bronze
- Lit les Ã©vÃ©nements Kafka
- Ã‰crit `/data/bronze/vehicles/part-*.parquet`
- 30 lignes minimum

### Silver
- Valide batterie (0-100)
- Valide coordonnÃ©es (lat: -90 Ã  90, lon: -180 Ã  180)
- Ã‰crit `/data/silver/vehicles/part-*.parquet`
- ~28-30 lignes (aprÃ¨s filtrage)

### Gold
- AgrÃ¨ge par type (car, bike, scooter)
- Calcule moyennes et min/max
- Ã‰crit `/data/gold/stats/part-*.parquet`
- 3 lignes (une par type)

## ğŸ› Troubleshooting

### Le Producer n'envoie pas de messages
```bash
# VÃ©rifier que Kafka est accessible
kubectl exec -it kafka-xxx -n lakehouse -- \\
  kafka-broker-api-versions --bootstrap-server localhost:9092
```

### Les Spark jobs ne trouvent pas les donnÃ©es
```bash
# VÃ©rifier le PersistentVolume
kubectl get pv
kubectl describe pv data-pv

# VÃ©rifier le PersistentVolumeClaim
kubectl get pvc -n lakehouse
```

### Pas de messages dans Kafka
```bash
# Regarde les logs du Producer
kubectl logs -n lakehouse job/producer-job

# Regarde les logs de Kafka
kubectl logs -n lakehouse kafka-xxx
```

## ğŸ“š Ressources

- [Kafka Documentation](https://kafka.apache.org/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Spark Documentation](https://spark.apache.org/)

---

**CrÃ©Ã© avec â¤ï¸ pour la migration Kubernetes**
'''
    )
    
    # ==================== BUILD SCRIPT ====================
    
    create_file(
        project_root / "build.sh",
        '''#!/bin/bash
# Script de build pour le projet Kubernetes

echo "ğŸš€ Build du projet Lakehouse Kubernetes"

# 1. Build le Producer
echo "\\nğŸ“¦ Build du Producer..."
cd producer
mvn clean package -DskipTests
if [ $? -eq 0 ]; then
    echo "âœ“ Producer compilÃ©"
    docker build -t producer:1.0 .
    echo "âœ“ Image Docker crÃ©Ã©e"
else
    echo "âŒ Erreur lors du build du Producer"
    exit 1
fi
cd ..

# 2. CrÃ©er le namespace
echo "\\nğŸ—ï¸  CrÃ©ation du namespace..."
kubectl create namespace lakehouse --dry-run=client -o yaml | kubectl apply -f -

# 3. DÃ©ployer Kafka
echo "\\nğŸ”Œ DÃ©ploiement de Kafka..."
kubectl apply -f kubernetes/kafka-deployment.yaml
kubectl apply -f kubernetes/topic-creation.yaml

# 4. Attendre que Kafka soit prÃªt
echo "\\nâ³ Attente de Kafka..."
sleep 30

# 5. DÃ©ployer le Producer
echo "\\nğŸ“¤ DÃ©ploiement du Producer..."
kubectl apply -f kubernetes/producer-job.yaml

echo "\\nâœ… Build complÃ¨te!"
echo "Commandes utiles:"
echo "  kubectl get pods -n lakehouse -w       # Voir les pods"
echo "  kubectl logs -n lakehouse <pod>        # Voir les logs"
echo "  kubectl delete namespace lakehouse     # Nettoyer"
'''
    )
    
    print("\n" + "="*60)
    print("âœ… PROJET CRÃ‰Ã‰ AVEC SUCCÃˆS!")
    print("="*60)
    print(f"\nğŸ“ Localisation: {project_root}")
    print("\nğŸ“‹ Fichiers crÃ©Ã©s:")
    print("  âœ“ Producer Java (avec Maven)")
    print("  âœ“ Jobs Spark Python (Bronze/Silver/Gold)")
    print("  âœ“ Configuration Kubernetes YAML")
    print("  âœ“ README complet")
    print("  âœ“ Build script")
    print("\nğŸš€ Prochaines Ã©tapes:")
    print("  1. cd C:/lakehouse-kubernetes-project")
    print("  2. mvn -v  # VÃ©rifier Maven")
    print("  3. docker build -t producer:1.0 producer/")
    print("  4. kubectl create namespace lakehouse")
    print("  5. kubectl apply -f kubernetes/")
    print("\nğŸ’¡ Besoin d'aide?")
    print("  - Lire le README.md")
    print("  - VÃ©rifier les YAML")
    print("  - Voir les logs avec kubectl logs")

if __name__ == "__main__":
    main()